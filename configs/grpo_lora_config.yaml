model_config:
  model_name_or_path: "Qwen/Qwen2.5-Math-1.5B"
  gpu_memory_utilization: 0.4
  dtype: "bfloat16"
  model_num_gpus: 0.5
  rollout_num_gpus: 0.5

  # LoRA settings, default none
  use_lora: true
  lora_rank: 32
  lora_alpha: 64
  lora_dropout: 0
  lora_target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']

generation_config:
  group_size: 8
  temperature: 1.0
  top_p: 0.9
  min_tokens: 4
  max_tokens: 1024
  stop_tokens:
    - "</answer>"
  
advantage_config:
  mode: 'grpo_no_std'
  advantage_eps: 1.0e-6

train_config:
  n_grpo_steps: 200
  train_dataset: "data/gsm8k/train.jsonl"
  eval_dataset: "data/gsm8k/test.jsonl"
  truncate_max_length: 2048
  learning_rate: 5.0e-5
  rollout_batch_size: 64
  epochs_per_rollout_batch: 1
  train_batch_size: 32
  micro_train_batch_size: 2
  
  # Optimizer settings
  adam_beta1: 0.9
  adam_beta2: 0.95
  gradient_checkpoint: true
  max_grad_norm: 1.0
  return_token_entropy: true

  # LR scheduler
  lr_scheduler_type: "constant"  # options: constant, cosine
  warmup_ratio: 0.1
  min_lr_ratio: 0.1

loss_config:
  loss_level: "token"  # options: token, sequence
  clip_range_left: 0.2
  clip_range_right: 0.3

wandb_config:
  enabled: true
  project: "reason-rl"
  entity: null
  run_name: null
  tags: ['token_level', 'grpo_no_std', 'gsm8k-math']
  log_interval: 1
  eval_interval: 10
  save_interval: 100
